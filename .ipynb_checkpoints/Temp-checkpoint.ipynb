{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob\n",
    "import sklearn\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('result.csv',index_col=['imdbID'], header=0)\n",
    "df = df[np.isfinite(df['Opening Weekend USA'])]\n",
    "df['BoxOffice'] = df['BoxOffice'].replace( '[\\$,)]','', regex=True ).astype(float)\n",
    "df['Production'] = [d.replace('/',',') for d in df['Production']]\n",
    "df['Director'] = [d.replace('(co-director)','') for d in df['Director']]\n",
    "df['Runtime'] = df['Runtime'].replace( 'min','', regex=True ).astype(int)\n",
    "df['Released'] = [a[3:6] for a in df['Released']]\n",
    "df['imdbRating'] = [round(r * 2) / 2 for r in df['imdbRating']]\n",
    "df['Oscar'] = [int(str.find('Oscar') > 0) for str in df['Awards']]\n",
    "df = shuffle(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding_column(df, col_name, delimiter=','):\n",
    "    item_map = {}\n",
    "    item_count = 0\n",
    "    movie_size = len(df)\n",
    "    for i in range(movie_size):\n",
    "        items = str(df[col_name].iloc[i])\n",
    "        items_arr = items.split(delimiter)\n",
    "        for item in items_arr:\n",
    "            item = item.strip()\n",
    "            if item not in item_map:\n",
    "                item_map[item] = item_count\n",
    "                item_count += 1\n",
    "\n",
    "    Matrix = [[0 for x in range(item_count)] for y in range(movie_size)] \n",
    "    for i in range(movie_size):\n",
    "        items = str(df[col_name].iloc[i])\n",
    "        items_arr = items.split(delimiter)\n",
    "        for item in items_arr:\n",
    "            item = item.strip()\n",
    "            idx = item_map[item]\n",
    "            Matrix[i][idx] = 1\n",
    "    return item_map, np.asarray(Matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_log_label (bins, box_office_value):\n",
    "    log_val = np.log(box_office_value)\n",
    "    for i in range(len(bins[1])):\n",
    "        if bins[1][i] <= log_val and log_val <= bins[1][i+1]:\n",
    "            return i\n",
    "    return len(bins[1]) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_prediction_matrix (bins, column_names, year):\n",
    "    \n",
    "    labels = [get_log_label(bins, o) for o in df['Opening Weekend USA']]\n",
    "    encoded_matrix = []\n",
    "    for column in column_names:\n",
    "        column_map, column_Matrix = one_hot_encoding_column(df,column)\n",
    "        encoded_matrix.append(column_Matrix)\n",
    "        \n",
    "    t_Matrix = np.concatenate(encoded_matrix, axis=1)     \n",
    "    x_train = t_Matrix[df['Year'] != year]\n",
    "    x_test = t_Matrix[df['Year'] == year ]\n",
    "    y_train = np.array(labels)[df['Year'] != year]\n",
    "    y_test = np.array(labels)[df['Year'] == year ]\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "\n",
    "def logistic_regression_model (bin_size,column_names, year, verbose=False):\n",
    "    bins = plt.hist(np.log(df['Opening Weekend USA']), bin_size)\n",
    "    x_train, x_test, y_train, y_test = setup_prediction_matrix (bins,column_names, year)\n",
    "    clf_l2_LR = LogisticRegression(multi_class=\"multinomial\", solver = 'lbfgs', \\\n",
    "        class_weight ='balanced', random_state = 2)\n",
    "    clf_l2_LR.fit(x_train, y_train)\n",
    "    y_predit = clf_l2_LR.predict(x_test)\n",
    "    if verbose:\n",
    "        print (\"Logistic regression with:\", bin_size, \"label classes,\", \"accuracy:\", np.mean(y_predit == y_test))\n",
    "    plt.close()\n",
    "    return bins \n",
    "    \n",
    "    \n",
    "def decision_tree_model (bin_size,column_names, year, verbose=False):\n",
    "    bins = plt.hist(np.log(df['Opening Weekend USA']), bin_size)\n",
    "    x_train, x_test, y_train, y_test = setup_prediction_matrix (bins,column_names, year)\n",
    "    \n",
    "    DTC = DecisionTreeClassifier()\n",
    "    DTC.fit(x_train, y_train)\n",
    "    y_predit = DTC.predict(x_test)\n",
    "    if verbose:\n",
    "        print (\"Decision Tree with:\", bin_size, \"label classes,\", \"accuracy:\", np.mean(y_predit == y_test))\n",
    "    plt.close()\n",
    "    return bins, DTC\n",
    "\n",
    "def random_forest_model (bin_size,column_names, year, verbose=False):\n",
    "    bins = plt.hist(np.log(df['Opening Weekend USA']), bin_size)\n",
    "    x_train, x_test, y_train, y_test = setup_prediction_matrix (bins,column_names, year)\n",
    "    \n",
    "    CLF = RandomForestClassifier()\n",
    "    CLF.fit(x_train, y_train)\n",
    "    y_predit = CLF.predict(x_test)\n",
    "    if verbose:\n",
    "        print (\"SVM with:\", bin_size, \"label classes,\", \"accuracy:\", np.mean(y_predit == y_test))\n",
    "    plt.close()\n",
    "    return bins, CLF\n",
    "\n",
    "    \n",
    "def show_bins(bins):\n",
    "     for i in range(len(bins[0])):\n",
    "        print (\"label\", i+1 , \":\",  np.exp(bins[1][i]), '-' ,np.exp(bins[1][i+1]), \",\" , str(bins[0][i]) , \"movies\")\n",
    "    \n",
    "features = ['Actors','Production', 'Director', 'Country', 'Rated', 'Released', 'Genre', 'imdbRating']\n",
    "\n",
    "#logistic_regression_model(2, 2017)\n",
    "#logistic_regression_model(4, 2017)\n",
    "#logistic_regression_model(8, features, 2017)\n",
    "#decision_tree_model(2, features, 2017)\n",
    "#decision_tree_model(4, features, 2017)\n",
    "#decision_tree_model(8, features, 2017)\n",
    "#svm_model(2, features, 2017)\n",
    "#bins, CLF = svm_model(4, features, 2017)\n",
    "\n",
    "#svm_model(8, features, 2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking for: Production\n",
      "1. Sony Pictures Classics (0.084816)\n",
      "2. Universal Pictures (0.051247)\n",
      "3. Warner Bros. Pictures (0.051029)\n",
      "4. 20th Century Fox (0.049313)\n",
      "\n",
      "Feature ranking for: Genre\n",
      "1. Drama (0.506969)\n",
      "2. Action (0.053715)\n",
      "3. Biography (0.049320)\n",
      "4. Romance (0.042706)\n",
      "\n",
      "Feature ranking for: Actors\n",
      "1. Kristin Scott Thomas (0.004973)\n",
      "2. Adam Sandler (0.004208)\n",
      "3. Johnny Depp (0.004190)\n",
      "4. Dwayne Johnson (0.004106)\n",
      "\n",
      "Feature ranking for: Director\n",
      "1. Tyler Perry (0.005018)\n",
      "2. Gus Van Sant (0.003602)\n",
      "3. Shawn Levy (0.002848)\n",
      "4. Ridley Scott (0.002830)\n",
      "\n",
      "Feature ranking for: Released\n",
      "1. Jan (0.364891)\n",
      "2. Sep (0.203495)\n",
      "3. May (0.202065)\n",
      "4. Apr (0.109755)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def feature_importance_study(column_name, year, df, bin_size, n):\n",
    "    \n",
    "    def recover_key(dicty, value):\n",
    "        for a_key in dicty.keys():\n",
    "            if (dicty[a_key] == value):\n",
    "                return a_key\n",
    "\n",
    "        \n",
    "    col_map, col_matrix = one_hot_encoding_column(df, column_name)\n",
    "    bins, CLF = decision_tree_model(n, [column_name], year)\n",
    "\n",
    "    importances = CLF.feature_importances_\n",
    "    indices = np.argsort(importances)[::-1]\n",
    "    print(\"Feature ranking for:\", column_name)\n",
    "    cc = 0\n",
    "    for f in range(col_matrix.shape[1]):\n",
    "        print(\"%d. %s (%f)\" % (f + 1, recover_key(col_map, indices[f]), importances[indices[f]]))  \n",
    "        if cc == n:\n",
    "            break\n",
    "        cc += 1\n",
    "    print (\"\")\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "feature_importance_study (\"Production\", 2017, df, 4, 3)\n",
    "feature_importance_study (\"Genre\", 2017, df, 4, 3)\n",
    "feature_importance_study (\"Actors\", 2017, df, 8, 3)\n",
    "feature_importance_study (\"Director\", 2017, df, 4, 3)\n",
    "feature_importance_study (\"Released\", 2017, df, 4, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score:  0.8527131782945736 \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Dunkirk is 85.74% positive, 14.26% negative to go to the Oscar.'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_matrix = []\n",
    "for column in features:\n",
    "    column_map, column_Matrix = one_hot_encoding_column(df,column)\n",
    "    encoded_matrix.append(column_Matrix)\n",
    "    \n",
    "t_Matrix = np.concatenate(encoded_matrix, axis=1)     \n",
    "x_train = t_Matrix[df['Year'] != 2017]\n",
    "x_test = t_Matrix[df['Year'] == 2017 ]\n",
    "\n",
    "y_train = [o for o in df[df['Year']!=2017]['Oscar']]\n",
    "y_test = [o for o in df[df['Year']==2017]['Oscar']]\n",
    "\n",
    "clf_l2_LR = LogisticRegression(multi_class=\"multinomial\", solver = 'lbfgs', \\\n",
    "        class_weight ='balanced', random_state = 2)\n",
    "clf_l2_LR.fit(x_train, y_train)\n",
    "y_predit = clf_l2_LR.predict(x_test)\n",
    "prob = clf_l2_LR.predict_proba(x_test)\n",
    "print (\"Accuracy score: \", clf_l2_LR.score(x_test, y_test), \"\\n\")\n",
    "\n",
    "prediction = {}\n",
    "for i in range (len(x_test)):\n",
    "    prediction[df[df['Year']==2017].iloc[i].Title] = (df[df['Year']==2017].iloc[i].Title+ \" is \" + \\\n",
    "                                                      str(round(prob[i][1] * 100,2)) + \"% positive, \"\\\n",
    "                                                      + str(round(prob[i][0]*100,2)) + \"% negative to go to the Oscar.\"  )\n",
    "\n",
    "\n",
    "prediction['Dunkirk']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
